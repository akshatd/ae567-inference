{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from typing import Callable, Tuple\n",
    "import functools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some useful utilities\n",
    "from mcmc_utils_and_plot import scatter_matrix, build_cov_mat, lognormpdf, plot_bivariate_gauss, eval_func_on_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Metropolis Hastings\n",
    "\n",
    "Log_pdf_t = Callable[[np.ndarray], float]  # log pdf type\n",
    "Log_pdfc_t = Callable[[np.ndarray, np.ndarray], float]  # conditional pdf types\n",
    "Sampler = Callable[[np.ndarray], np.ndarray]  # conditional sampler type\n",
    "\n",
    "\n",
    "def mh_acceptance_prob(current_target_logpdf: float,\n",
    "                       proposed_target_logpdf: float,\n",
    "                       current_sample: np.ndarray,\n",
    "                       proposed_sample: np.ndarray,\n",
    "                       proposal_func: Log_pdfc_t) -> float:\n",
    "    \"\"\"Compute the metropolis-hastings accept-reject probability.\n",
    "\n",
    "    Args:\n",
    "        current_target_logpdf: float, logpdf at the current sample in the chain f_X(x^{(k)})\n",
    "        proposed_target_logpdf: float, logpdf at the proposed sample in the chain\n",
    "        current_sample: (d, ), current sample\n",
    "        proposed_sample: (d, ), proposed sample\n",
    "        proposal_func: f(x, y) callable that gives the log probability of y given x\n",
    "\n",
    "    Returns:\n",
    "        acceptance probability\n",
    "    \"\"\"\n",
    "\n",
    "    prop_reverse = proposal_func(proposed_sample, current_sample)\n",
    "    prop_forward = proposal_func(current_sample, proposed_sample)\n",
    "    check = proposed_target_logpdf - current_target_logpdf + prop_reverse - prop_forward  # check this\n",
    "    if check < 0:\n",
    "        return np.exp(check)\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "def mh(starting_sample: np.ndarray,\n",
    "       num_samples: int,\n",
    "       target_logpdf: Log_pdf_t,\n",
    "       proposal_logpdf: Log_pdfc_t,\n",
    "       proposal_sampler: Sampler) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Metropolis-Hastings MCMC.\n",
    "\n",
    "    Args:\n",
    "        starting_sample: (d, ) the initial sample\n",
    "        num_sample: positive integer, the number of total samples\n",
    "        target_logpdf: function(x) -> logpdf of the target distribution\n",
    "        proposal_logpdf: function (x, y) -> logpdf of proposing y if current sample is x\n",
    "        proposal_sampler: function (x) -> y, generate a sample if you are currently at x\n",
    "\n",
    "    Returns:\n",
    "        Samples: (num_samples, d) array of samples\n",
    "        accept_ratio: ratio of proposed samples that were accepted\n",
    "    \"\"\"\n",
    "\n",
    "    d = starting_sample.shape[0]\n",
    "    samples = np.zeros((num_samples, d))\n",
    "    samples[0, :] = starting_sample\n",
    "    current_target_logpdf = target_logpdf(samples[0, :])\n",
    "\n",
    "    num_accept = 0\n",
    "    for ii in range(1, num_samples):\n",
    "        # propose\n",
    "        proposed_sample = proposal_sampler(samples[ii-1, :])\n",
    "        proposed_target_logpdf = target_logpdf(proposed_sample)\n",
    "\n",
    "        # determine acceptance probability\n",
    "        a = mh_acceptance_prob(current_target_logpdf, proposed_target_logpdf,\n",
    "                               samples[ii-1, :], proposed_sample, proposal_logpdf)\n",
    "\n",
    "        # Accept or reject the sample\n",
    "        if a == 1:  # guaranteed to accept\n",
    "            samples[ii, :] = proposed_sample\n",
    "            current_target_logpdf = proposed_target_logpdf\n",
    "            num_accept += 1\n",
    "        else:\n",
    "            u = np.random.rand()\n",
    "            if u < a:  # accept\n",
    "                samples[ii, :] = proposed_sample\n",
    "                current_target_logpdf = proposed_target_logpdf\n",
    "                num_accept += 1\n",
    "            else:  # reject\n",
    "                samples[ii, :] = samples[ii-1, :]\n",
    "\n",
    "    return samples, num_accept / float(num_samples-1)\n",
    "\n",
    "# 1 Adaptive Metropolis Hastings\n",
    "# 2. Delayed Rejection\n",
    "# 3. Delayed Rejection Adaptive Metropolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Target (Banana distribution)\n",
    "def banana_logpdf(x):\n",
    "    a = 1.0\n",
    "    b = 100.0\n",
    "    logpdf = -(a-x[0])**2 - b * (x[1] - x[0]**2)**2\n",
    "    # logpdf = np.exp(-0.5 * (x[0])**2 + x[1]**2) - np.exp(-0.5 / 1.0 * (x[0]**2 + x[1]**2))\n",
    "    # logpdf = np.log(logpdf)\n",
    "    # logpdf = (np.sin(10*x[0]*x[1]) + x[1]**2)*4\n",
    "    return logpdf\n",
    "    # return logpdf\n",
    "# Proposal functions\n",
    "\n",
    "\n",
    "def proposal_rw_sampler(x: np.ndarray, std: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Sample from a random walk proposal with identity covariance.\"\"\"\n",
    "    y = std * np.random.randn(x.shape[0]) + x\n",
    "    return y\n",
    "\n",
    "\n",
    "def proposal_rw_logpdf(x: np.ndarray, y: np.ndarray, std: float = 1.0) -> np.ndarray:\n",
    "    \"\"\"Probability of moving from x to y (in this case it is symmetric).\"\"\"\n",
    "    delta = x - y\n",
    "    logpdf = -0.5 * np.dot(delta, delta) / std / std\n",
    "    return logpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the sampling methods\n",
    "\n",
    "num_samples = 100000\n",
    "dim = 2  # do not change cos banana is only defined for 2D\n",
    "initial_sample = np.random.randn(dim)  # random location\n",
    "# initial_sample = np.array([10, 10])\n",
    "\n",
    "target_logpdf = banana_logpdf\n",
    "\n",
    "\n",
    "def p_sampler(x): return proposal_rw_sampler(x, std=3e-1)  # 3e-1\n",
    "def p_eval(x, y): return proposal_rw_logpdf(x, y, std=3e-1)\n",
    "\n",
    "\n",
    "s_mh, ar_mh = mh(initial_sample, num_samples, target_logpdf, p_eval, p_sampler)\n",
    "# s_am, ar_am = am(initial_sample, num_samples, target_logpdf, p_eval, p_sampler)\n",
    "# s_dr, ar_dr = dr(initial_sample, num_samples, target_logpdf, p_eval, p_sampler)\n",
    "# s_dram, ar_dram = dram(initial_sample, num_samples, target_logpdf, p_eval, p_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis functions\n",
    "\n",
    "def autocorrelation(samples: np.ndarray, maxlag: int = 100, step: int = 1):\n",
    "    \"\"\"Compute the correlation of a set of samples.\n",
    "\n",
    "    Args:\n",
    "        samples: (N, d)\n",
    "        maxlag: maximum distance to compute the correlation for\n",
    "        step: step between distances from 0 to maxlag for which to compute the correlations\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shapes\n",
    "    ndim = samples.shape[1]\n",
    "    nsamples = samples.shape[0]\n",
    "\n",
    "    # Compute the mean\n",
    "    mean = np.mean(samples, axis=0)\n",
    "\n",
    "    # Compute the denominator, which is variance\n",
    "    denominator = np.zeros((ndim))\n",
    "    for ii in range(nsamples):\n",
    "        denominator = denominator + (samples[ii, :] - mean)**2\n",
    "\n",
    "    lags = np.arange(0, maxlag, step)\n",
    "    autos = np.zeros((len(lags), ndim))\n",
    "    for zz, lag in enumerate(lags):\n",
    "        autos[zz, :] = np.zeros((ndim))\n",
    "        # compute the covariance between all samples *lag apart*\n",
    "        for ii in range(nsamples - lag):\n",
    "            autos[zz, :] = autos[zz, :] + (samples[ii, :]-mean)*(samples[ii + lag, :] - mean)\n",
    "        autos[zz, :] = autos[zz, :]/denominator\n",
    "    return lags, autos\n",
    "\n",
    "\n",
    "def autocorr_fast(samples: np.ndarray, maxlag: int = 100, step: int = 1):\n",
    "    \"\"\"Compute the correlation of a set of samples.\n",
    "\n",
    "    Args:\n",
    "        samples: (N, d)\n",
    "        maxlag: maximum distance to compute the correlation for\n",
    "        step: step between distances from 0 to maxlag for which to compute the correlations\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shapes\n",
    "    ndim = samples.shape[1]\n",
    "\n",
    "    # Compute the mean\n",
    "    mean = np.mean(samples, axis=0)\n",
    "\n",
    "    denominator = np.sum((samples - mean)**2, axis=0)\n",
    "\n",
    "    lags = np.arange(0, maxlag, step)\n",
    "    autos = np.zeros((len(lags), ndim))\n",
    "    autos[0, :] = denominator * np.ones((ndim))  # lag 0 has max autocorrelation of 1\n",
    "    for zz, lag in enumerate(lags[1:]):  # skip the lag of 0\n",
    "        autos[zz+1, :] = np.sum((samples[:-lag, :] - mean) * (samples[lag:, :] - mean), axis=0)\n",
    "    autos = autos/denominator\n",
    "    return lags, autos\n",
    "\n",
    "\n",
    "def autocorr_test(samples: np.ndarray, maxlag: int = 100, step: int = 1):\n",
    "    lags1, autolag1 = autocorrelation(samples, maxlag=maxlag, step=step)\n",
    "    lags2, autolag2 = autocorr_fast(samples, maxlag=maxlag, step=step)\n",
    "    assert np.allclose(autolag1, autolag2), \"Autocorrelation functions are not the same\"\n",
    "    assert np.allclose(lags1, lags2), \"Lags are not the same\"\n",
    "\n",
    "\n",
    "def get_iacs(sampless):\n",
    "    iacs = []\n",
    "    for samples in sampless:\n",
    "        maxlag = samples.shape[0]\n",
    "        _, autolag = autocorr_fast(samples, maxlag=maxlag, step=1)\n",
    "        iacs.append(1 + 2*np.sum(autolag, axis=0))\n",
    "    return iacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautocorr_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_mh\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 62\u001b[0m, in \u001b[0;36mautocorr_test\u001b[0;34m(samples, maxlag, step)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mautocorr_test\u001b[39m(samples: np\u001b[38;5;241m.\u001b[39mndarray, maxlag: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, step: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 62\u001b[0m     lags1, autolag1 \u001b[38;5;241m=\u001b[39m \u001b[43mautocorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     lags2, autolag2 \u001b[38;5;241m=\u001b[39m autocorr_fast(samples, maxlag\u001b[38;5;241m=\u001b[39mmaxlag, step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(autolag1, autolag2), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutocorrelation functions are not the same\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36mautocorrelation\u001b[0;34m(samples, maxlag, step)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# compute the covariance between all samples *lag apart*\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nsamples \u001b[38;5;241m-\u001b[39m lag):\n\u001b[0;32m---> 30\u001b[0m         autos[zz, :] \u001b[38;5;241m=\u001b[39m autos[zz, :] \u001b[38;5;241m+\u001b[39m (samples[ii, :]\u001b[38;5;241m-\u001b[39mmean)\u001b[38;5;241m*\u001b[39m(samples[ii \u001b[38;5;241m+\u001b[39m lag, :] \u001b[38;5;241m-\u001b[39m mean)\n\u001b[1;32m     31\u001b[0m     autos[zz, :] \u001b[38;5;241m=\u001b[39m autos[zz, :]\u001b[38;5;241m/\u001b[39mdenominator\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lags, autos\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# autocorr_test(s_mh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "# samples = [s_mh, s_am, s_dr, s_dram]\n",
    "sampless = [s_mh]\n",
    "\n",
    "# titles = [\"Metropolis Hastings\", \"Adaptive Metropolis\",\n",
    "#             \"Delayed Rejection\", \"Delayed Rejection Adaptive Metropolis\"]\n",
    "titles = [\"Metropolis Hastings\"]\n",
    "\n",
    "# Autocorrelation\n",
    "\n",
    "MAXLAG = 1000\n",
    "STEP = 10\n",
    "\n",
    "lags_auto = []\n",
    "autolags = []\n",
    "for samples in sampless:\n",
    "    lags, autolag = autocorr_fast(samples, maxlag=MAXLAG, step=STEP)\n",
    "    lags_auto.append(lags)\n",
    "    autolags.append(autolag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iacs = get_iacs(sampless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Helper functions\n",
    "\n",
    "\n",
    "def plot_marginal(plt_id, sampless, titles):\n",
    "    for samples, title in zip(sampless, titles):\n",
    "        plt.close(plt_id)\n",
    "        fig, _, _ = scatter_matrix(plt_id, [samples], labels=[r'$x_1$', r'$x_2$'],\n",
    "                                   hist_plot=True, gamma=0.2, nbins=70, title=f'Marginal: {title}')\n",
    "        plt.show()\n",
    "        fig.savefig(f'figs/marginal_{title}.svg')\n",
    "        plt_id += 1\n",
    "\n",
    "    return plt_id\n",
    "\n",
    "\n",
    "def plot_autocorrelation(plt_id, lagss, autolags, titles):\n",
    "    n_plots = len(lagss)\n",
    "    plt.close(plt_id)\n",
    "    fig, axs = plt.subplots(n_plots, 2, figsize=(8, n_plots*2.5), num=plt_id)\n",
    "    fig.tight_layout(pad=3)\n",
    "    fig.suptitle('Autocorrelation', fontsize=14)\n",
    "    for i, (lags, autolag, title) in enumerate(zip(lagss, autolags, titles)):\n",
    "        # ax1 = axs[i*2, 0]\n",
    "        # ax2 = axs[i*2, 1]\n",
    "        ax1 = axs[0]\n",
    "        ax2 = axs[1]\n",
    "        ax1.plot(lags, autolag[:, 0], '-o')\n",
    "        ax1.set_xlabel('Lag')\n",
    "        ax1.set_ylabel('Autocorrelation')\n",
    "        ax1.set_title(title + r\" $x_1$\")\n",
    "        ax2.plot(lags, autolag[:, 1], '-o')\n",
    "        ax2.set_xlabel('Lag')\n",
    "        ax2.set_ylabel('Autocoorelation')\n",
    "        ax2.set_title(title + r\" $x_2$\")\n",
    "    plt.show()\n",
    "    fig.savefig('figs/autocorrelation.svg')\n",
    "    plt_id += 1\n",
    "    return plt_id\n",
    "\n",
    "\n",
    "def plot_inspection(plt_id, sampless, titles):\n",
    "    n_plts = len(sampless)\n",
    "    plt.close(plt_id)\n",
    "    fig, axs = plt.subplots(n_plts, 2, figsize=(8, n_plts*2.5), num=plt_id)\n",
    "    fig.tight_layout(pad=3)\n",
    "    fig.suptitle('Visual Inspection of Mixing', fontsize=14)\n",
    "    for i, (samples, title) in enumerate(zip(sampless, titles)):\n",
    "        # ax1 = axs[i*2, 0]\n",
    "        # ax2 = axs[i*2, 1]\n",
    "        ax1 = axs[0]\n",
    "        ax2 = axs[1]\n",
    "        ax1.plot(samples[:, 0], '-k')\n",
    "        ax1.set_xlabel('Sample Number')\n",
    "        ax1.set_ylabel('Value')\n",
    "        ax1.set_title(title + r\" $x_1$\")\n",
    "        ax2.plot(samples[:, 1], '-k')\n",
    "        ax2.set_xlabel('Sample Number')\n",
    "        ax2.set_ylabel('Value')\n",
    "        ax2.set_title(title + r\" $x_2$\")\n",
    "    plt.show()\n",
    "    fig.savefig('figs/inspection.svg')\n",
    "    plt_id += 1\n",
    "    return plt_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Plot everything\n",
    "plt_id = 1\n",
    "# 5.a Plots of 1D and 2D marginals\n",
    "plt_id = plot_marginal(plt_id, sampless, titles)\n",
    "\n",
    "# 5.b Autocorrelation plots\n",
    "plt_id = plot_autocorrelation(plt_id, lags_auto, autolags, titles)\n",
    "\n",
    "# 5.c Integrated autocorrelation values\n",
    "print(f\"Integrated autocorrelation values:\")\n",
    "for iac, title in zip(iacs, titles):\n",
    "    print(f\"- {title}: {iac}\")\n",
    "\n",
    "# 5.d Acceptance ratio\n",
    "print(f\"Acceptance ratio:\")\n",
    "print(f\"- Metropolis Hastings: {ar_mh*100:.0f}%\")\n",
    "# print(f\"- Adaptive Metropolis: {ar_am*100:.0f}%\")\n",
    "# print(f\"- Delayed Rejection: {ar_dr*100:.0f}%\")\n",
    "# print(f\"- Delayed Rejection Adaptive Metropolis: {ar_dram*100:.0f}%\")\n",
    "\n",
    "# 5.e Visual inspection of mixing\n",
    "plt_id = plot_inspection(plt_id, sampless, titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "567repo-ITb6N_oG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
