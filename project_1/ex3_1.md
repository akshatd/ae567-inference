---
geometry: "margin=2cm"
---

$\pagebreak$

## 3.1 1-D Bernoulli random walk

### 2.1.a

A random walk is implemented by:

- Take a random number from a uniform distribution in $[0, 1)$.
- if the number is less than 0.5, take a step = -1, else take a step = 1.
- The walk $S$ is the cumulative sum of these steps, as described in the problem

Visualization of an N-step 1-D Bernoulli random walk, with $n=1000$ steps.

![1-D Bernoulli random walk vs n](figs/3.1.svg){width=60%}

### 2.1.b

To perform a Monte Carlo estimate of $\mathbb P(S>10)$:

- Simulate the random walk $10^5$ times with 100 steps.
- Count the number of times the walk exceeds 10 (our indicator function) $1_A(x)$:

  $$
  1_A^{10} = \left\{ \begin{array}{ll}
  				 1 & \mbox{if $S > 10$}\\
  				0 & \mbox{if $S \leq 10$}\end{array} \right..
  $$

- The probability is then the ratio of the number of times the walk exceeds 10 to the total number of trials.

$$
\begin{aligned}
\mathbb P(S>10) &= \frac{1}{n} \sum_{i=1}^{n} 1_A(x)\\
\end{aligned}
$$

Monte Carlo estimate with $10^5$ trials with 1000 steps in each walk for $\mathbb P(S>10)$ = 0.13579

$\pagebreak$

### 2.1.c

Before performing importance sampling, lets take a look at the distribution of the random walk with 100 steps.

![1-D Bernoulli random walk distribution](figs/3.2.svg){width=60%}

The distribution has

- Mean = 0.0838
- Variance = 100.63476096000001

As expected from a random walk, the distribution is normal with a mean $\approx 0$ and a standard deviation $\approx$ the number of time steps, which is the same as the number of steps in our case since we are not shrinking the time. However, we see that the probability of the walk exceeding 55 is very low, which makes it a good candidate for importance sampling.

For this problem we change our indicator function to:

$$
1_A^{55} = \left\{ \begin{array}{ll}
				 1 & \mbox{if $S > 55$}\\
				0 & \mbox{if $S \leq 55$}\end{array} \right..
$$

Our original distribution is a random walk with a probability of $\mathbb P(X_j = 1) = \mathbb P(X_j = -1) = 0.5$. If we simply perform Monte Carlo on the original distribution using the new $1_A$, we get a probability of 0 with the same number of trials, confirming what we saw in the probability distribution figure above.

To perform the importance sampling, intuitively we need a proposal distribution that has a high probability of exceeding 55. We can just use another random walk with a the probability $\mathbb P(X_j = 1) > \mathbb P(X_j = -1)$. If we ensure that the expected value of this new distribution is around 55, we can ensure that at least half the samples will exceed 55 so we can get a better estimate. To calculate the new probability for 100 steps, we can use a simple formula to estimate the value of a random walk given a probability $p$ :

$$
\begin{aligned}
\sum_{i=1}^{100} (p)(1) + (1-p)(-1) &> 55 \\
100(2p - 1) &> 55 \\
p &> 0.775
\end{aligned}
$$

So, if the original distribution was $\mathbb P(X_j = 1) = \mathbb P(X_j = -1) = 0.5$ with PDF as

$$
\begin{aligned}
f(S) &= p^k (1-p)^{100-k}
&= 0.5^{100}
\end{aligned}
$$

The proposal distribution can be $\mathbb P(X_j = 1) = 0.8, \mathbb P(X_j = -1) = 0.2$ with PDF as

$$
\begin{aligned}
\pi(S) &= p^k (1-p)^{100-k}
&= 0.8^k (0.2)^{100-k}
\end{aligned}
$$

Where $k$ is the number of +1 steps taken in the random walk $S$.

So we can use $\pi(S)$ to get a better estimate for $S>55$.

More formally, the expectation can be re-written as:

$$
\begin{aligned}
\mathbb P(S>55) &= \mathbb E_{f}[1_A^{55}(S)]\\
&= \int 1_A^{55}(S) f(S) dx\\
&= \int 1_A^{55}(S) \frac{f(S)}{\pi(S)} \pi(S) dx\\
&= \int 1_A^{55}(S) w(S) g(S) dx\\
&= \mathbb E_{\pi}[1_A^{55}(S) w(S)]\\
\end{aligned}
$$

And we can perform Monte Carlo on this new distribution like before, taking samples from the proposal distribution instead of the original distribution to calculate 1_A^{55}. We can then multiply them by the weights. The Importance sampling estimate for $\mathbb P(S>55) = 7.966439961067404e-09$.

Interestingly, increasing the $\mathbb P(X_j = 1)$ too high in the prposal distribution closer to 0.9 actually causes the MC with importance sampling estimate to become worse and stray away further from the analytical estimate. This could be explained by the fact that the proposal distribution gets too far from the original distribution, outputting values that are very high with extremely low probabilities in the original distribution. This makes the weights $w(x) \sim 0$, giving us no additional information. At the extreme, if we set this to 1, then the MC with importance sampling estimate becomes 0, which is not correct. So it makes sense to keep it close to the original distribution at 0.8.

$\pagebreak$

### 2.1.d

Analytical expression for the probability of the random walk exceeding a threshold $T$ is a simple probability calculation for a binomial distribution:

$$
\mathbb P(S>T) = \sum_{i=T+1}^{100} \mathbb P(S = i) \\
$$

For $\mathbb P(S=i)$ we would have $j$ steps with +1 and $100-j$ steps with -1. Then this must hold true for $i, j$:

$$
\begin{aligned}
j - (100-j) &= i \\
2j - 100 &= i \\
j &= \frac{i+100}{2} \\
\end{aligned}
$$

Take note that we can only choose an integer from another integer, so values of j that are fractions will be ignored. This will happen when $i$ is odd, and there is no way for this random walk to generate a final step that is odd.

For n steps $\mathbb P(S=i)$ becomes:

$$
\begin{aligned}
\mathbb P(S=i) &= {100 \choose j} p^j (1-p)^{100-j}\\
substituting \quad p = (1-p) = 0.5\\
&= {100 \choose j} 0.5^{100}\\
substituting \quad j = \frac{i+100}{2} \\
&= {100 \choose \frac{i+100}{2}} 0.5^{100}\\
\end{aligned}
$$

Substituting this into $\mathbb P(S>T)$:

$$
\mathbb P(S>T) = \sum_{i=T+1}^{100} {100 \choose \frac{i+100}{2}} 0.5^{100}
$$

When $T=10$, evaluating this expression gives us $\mathbb P(S>10) = 1.356265e-01$, which is very close to the Monte Carlo estimate with a difference of only 0.16%.

When $T=55$, evaluating this expression gives us $\mathbb P(S>55) = 7.95266423689307e-09$, which is very close to the MC with importance sampling estimate with a difference of only 0.17%.

$\pagebreak$

### 2.1.e.i

Standard errors for the estimates can be calculated as follows:

#### Monte Carlo for $\mathbb P(S>10)$:

Reference: Notes Page 56

$\\$

Using $1_A^{10}(S)$ is the indicator function for the event $\mathbb P(S>10)$:

$$
\begin{aligned}
Var[S_n] &= \frac{1}{n} Var[1_A^{10}(S)]\\
std\quad error &= \sqrt{\frac{Var[1_A^{10}(S)]}{n}}\\
\end{aligned}
$$

Or alternatively, using the analytical probability of $p = \mathbb P(S>10)$:

$$
std\quad error = \sqrt{\frac{p(1-p)}{n}}\\
$$

Both evaluate to a similar result:

- Using indicator function: $1.083489e-03$
- Analytical using $p$ : $1.082737e-03$

#### MC with Importance Sampling for $\mathbb P(S>55)$:

Reference: Notes Page 58

$$
\begin{aligned}
Var[S_n^{IS}]  &= \frac{1}{n} Var[1_A^{55}(S) w(S)]\\
std\quad error &= \sqrt{\frac{Var[1_A^{55}(S) w(S)]}{n}}\\
\end{aligned}
$$

$1_A^{55}(S)$ is the indicator function for the event $\mathbb P(S>55)$ and $w(S)$ is the weight for each sample calculated by dividing the original probability by the proposal probability. This evaluates to:

- MC with Importance Sampling standard error = 6.003709e-11

Reference: Notes Page 48

For calculating the 95% confidence intervals using the central limit theorem, we need to first normalize the estimates so they become $\sim \mathcal{N}(0,1)$ as $n \to \infty$. This is done by subtracting the mean and dividing by the standard deviation to get the normalized estimate, $H_n$:

$$
H_n = \frac{S_n - \mathbb \mu}{\sigma/\sqrt{n}}\\
$$

A confidence interval is defined as the interval $[-z, z]$ such that $P_X(H_n \in [-z, z]) \geq 1 - \delta$ where $z$ is the z-score for the desired confidence level and $1 - \delta$ is the confidence level. For a 95% confidence interval, $1 - \delta = 0.95$ and $z = 1.96$ for $\mathcal{N}(0,1)$, which is a standard quantity that can be obtained from various online sources and from `scipy.stats.norm.ppf`. Simplifying the expression for the probability defined above:

$$
\begin{aligned}
P_X(H_n \in [-z, z]) &= P_X(-z \leq H_n \leq z)\\
&= P_X(-z \leq \frac{S_n - \mathbb \mu}{\sigma/\sqrt{n}} \leq z)\\
&= P_X(\frac{-z\sigma}{\sqrt{n}} \leq S_n - \mu \leq + \frac{z\sigma}{\sqrt{n}})\\
&= P_X(-S_n - \frac{z\sigma}{\sqrt{n}} \leq - \mu \leq -S_n + \frac{z\sigma}{\sqrt{n}})\\
&= P_X(S_n + \frac{z\sigma}{\sqrt{n}} \geq \mu \geq S_n - \frac{z\sigma}{\sqrt{n}})\\
&= P_X(S_n - \frac{z\sigma}{\sqrt{n}} \leq \mu \leq S_n + \frac{z\sigma}{\sqrt{n}})\\
\end{aligned}
$$

The standard error calculated earlier is just $\frac{\sigma}{\sqrt{n}}$, which makes it easy to calculate this. The 95% confidence intervals calculated for the Monte Carlo and Importance Sampling estimates are:

- Monte Carlo for $\mathbb P(S>10)$ = [0.1337263621371712, 0.1379736378628288]
- MC with Importance Sampling for $\mathbb P(S>55)$ = [7.848767266908999e-09, 8.084112655225919e-09]

### 2.1.e.ii

Number of confidence intervals that contain the true value of the probability:

- Monte Carlo: 945
- MC with Importance Sampling: 956

The number of confidence intervals that contain the true value of the probability is very close to the expected value of 950 for both methods for a 95% confidence interval.

### 2.1.e.iii

To get the empirical 95% band, we can use the 2.5 and 97.5 percentiles of the at each step of the sequence of estimates. To get the CLT 95% confidence interval for the Monte Carlo estimates at each step in the sequence, we can just pick one of the replicas and calculate the confidence interval for that replica. This is because the standard error should be similar for all replicas, and the confidence interval is just a function of the standard error. Take note that for calculating the CLT 95% confidence interval, we take the mean as the analytical mean, and all the calculations are done in the same way as in part **2.1.e.i**.

Plotting an envelope of sequences of Monte Carlo estimates for $\mathbb P(S>10)$ and MC with Importance sampling for $\mathbb P(S>55)$. Black represents the envelope, Blue shaded region represents the empirical 95% band and the dotted red line represents the 95% CLT confidence interval.

**Note**: I was not able to run the code for more then 100 replicas, hence the graph is not very smooth. However, the general trend is still visible. I have made my conclusions based on what the graph would look like if I had 1000 replicas.

![Envelope of sequences of Monte Carlo vs M](figs/3.3.svg)

For both Estimators, as the number of trials increases, the bound gets tighter, which is expected as variance for a Monte Carlo estimator decreases as the number of trials increases. The envelope of sequences of Monte Carlo estimates for $\mathbb P(S>10)$ is much wider than the envelope of sequences of MC with Importance sampling for $\mathbb P(S>55)$, which is expected since the standard error for the MC with Importance sampling is much lower than the standard error for the Monte Carlo estimate. We can see that the empirical and CLT 95% envelope are very close to each other, and they get closer as the number of trials increases. This proves that the CLT 95% confidence interval is a good approximation for the empirical 95% band.
